# Week 02 Assignment

This directory contains my solution for Week 2.

## How to run

```bash
# (optional) create a virtual environment first
# python -m venv .venv && source .venv/bin/activate

pip install -r requirements.txt
python bandit_hw.py
```

Running the script will produce and save `figure_2_2_with_gradient.png` in this folder.

## Answers

### 1) Reimplement an MDP framework and reproduce Figure 2.2

- I implemented a minimal environment interface (`Env`) and a stationary **k-armed Bandit** environment (`Bandit`) from scratch.
- I implemented an **ε-greedy agent** with **sample-average** updates and reproduced the three curves in the book’s Figure 2.2 (`ε=0, 0.01, 0.1`), plotting **% Optimal Action** over time.

**Code:** [`bandit_hw.py`](./bandit_hw.py) — classes `Env`, `Bandit`, `EpsilonGreedyAgent`; function `simulate()` and `main()`.

**Figure output:** `figure_2_2_with_gradient.png` (generated by running the script).

### 2) Implement gradient policy learning for multi-armed bandits

- I implemented **Gradient Bandit** with a softmax policy over preferences `H`, with an optional **baseline** equal to the running average reward.
- I added **four series** to the same plot to evaluate:
  - no baseline, `α=0.1`
  - no baseline, `α=0.4`
  - with baseline, `α=0.1`
  - with baseline, `α=0.4`

**Code:** `GradientBanditAgent` in [`bandit_hw.py`](./bandit_hw.py).

### Notes

- Defaults: `runs=2000`, `steps=1000`, fixed random seed inside `main()`.
- The y-axis is plotted as **percentage** of optimal action to match the book.
